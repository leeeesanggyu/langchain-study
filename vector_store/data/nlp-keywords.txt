natural language processing: 인간의 언어를 컴퓨터가 이해하고 처리하도록 하는 기술
tokenization: 문장을 단어나 토큰 단위로 분리하는 전처리 작업
named entity recognition: 문장에서 사람, 장소, 조직 등 고유명사를 식별하는 기술
transformer models: 어텐션 메커니즘 기반의 최신 딥러닝 언어 모델 구조
BERT: 양방향 문맥을 이해하는 사전 학습된 언어 모델
GPT: 대규모 언어 생성에 특화된 트랜스포머 기반 모델
embedding vectors: 단어를 고차원 벡터 공간에 매핑한 표현 방식
cosine similarity: 두 벡터 사이의 유사도를 코사인 각도로 계산하는 방법
semantic search: 의미 기반으로 문서를 검색하는 기술
text classification: 텍스트를 사전 정의된 카테고리로 분류하는 작업
language modeling: 다음에 올 단어를 예측하기 위해 언어의 확률 분포를 학습하는 작업
text generation: 주어진 입력에 따라 자연어 텍스트를 생성하는 기술
dependency parsing: 문장 내 단어 간의 문법적 관계를 분석하는 기술
lemmatization: 단어를 기본형으로 환원하는 전처리 기법
part-of-speech tagging: 각 단어의 품사를 식별하고 태깅하는 작업
sentence segmentation: 텍스트를 문장 단위로 나누는 전처리 과정
attention mechanism: 입력의 특정 부분에 집중하여 처리 효율을 높이는 메커니즘
word2vec: 단어를 벡터로 표현하기 위한 예전 딥러닝 모델
vector space model: 문서나 단어를 벡터 공간 상에 배치하여 비교하는 모델
contextual embeddings: 문맥에 따라 의미가 달라지는 단어를 표현하는 임베딩
